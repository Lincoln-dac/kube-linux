可以通过 --metric-allowlist 或者 --metric-denylist 参数进行过滤。但是如果即使过滤了不需要的指标或标签后指标接口数据仍然非常大又该怎么办呢？

其实我们可以想象一下，无论怎么过滤，请求一次到达 metrics 接口后的数据量都是非常大的，这个时候是不是只能对指标数据进行拆分了，可以部署多个 KSM 实例，每个实例提供一部分接口数据，
是不是就可以缓解压力了，这其实就是我们常说的水平分片。为了水平分片 kube-state-metrics，它已经实现了一些自动分片功能，它是通过以下标志进行配置的：

--shard (从 0 开始)
--total-shards
分片是通过对 Kubernetes 对象的 UID 进行 MD5 哈希和对总分片数进行取模运算来完成的，每个分片决定是否由 kube-state-metrics 的相应实例处理对象。不过需要注意的是，kube-state-metrics
的所有实例，即使已经分片，也会处理所有对象的网络流量和资源消耗，而不仅仅是他们负责那部分对象，要优化这个问题，Kubernetes API 需要支持分片的 list/watch 功能。在最理想的情况下，
每个分片的内存消耗将比未分片设置少 1/n。通常，为了使 kube-state-metrics 能够迅速返回其指标给 Prometheus，需要进行内存和延迟优化。减少 kube-state-metrics 和 kube-apiserver 
之间的延迟的一种方法是使用 --use-apiserver-cache 标志运行 KSM，除了减少延迟，这个选项还将导致减少对 etcd 的负载，所以我们也是建议启用该参数的。

对于其他的指标我们也可以使用 --resource 来单独指定部署，也可以继续使用分片的方式。总结来说就是对于大规模集群使用 kube-state-metrics 需要做很多优化：

过滤不需要的指标和标签
通过分片降低 KSM 实例压力
可以使用 DaemonSet 方式单独针对 pod 指标进行部署
当然可能也有人会问，如果自己的业务指标也超级大的情况下该怎么办呢？当然就得让业务方来做支持了，首先要明确指标数据这么大是否正常？如果需求就是如此，那么也得想办法能够支持分片。

https://mp.weixin.qq.com/s/rUzUyvOxMua7-ucMuhNBNA
