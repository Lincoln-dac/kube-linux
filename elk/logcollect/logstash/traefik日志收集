input {
  kafka {
    bootstrap_servers => "10.204.51.65:9092"
    partition_assignment_strategy => "org.apache.kafka.clients.consumer.RoundRobinAssignor"
    group_id => "elk-traefik-logs"
    topics => ["elk-traefik-log"]
    consumer_threads => 3
    codec => json
    auto_offset_reset => "latest"
    max_poll_records => '500'
  }
}
filter {
  grok {
    match => { "message" => "%{IP:ip_address} %{USERNAME} %{USERNAME} \[%{HTTPDATE:timestamp}\] \"%{WORD:http_method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code:int} %{NUMBER:bytes:int} \"%{DATA:http_referer}\" \"%{DATA:user_agent}\" %{NUMBER:filed1:int} \"%{DATA:Ingressroute_name}\" \"%{DATA:POD_IP}\" %{NUMBER:response_time:int}ms" }
  }
}
output {
  elasticsearch {
    hosts => ["http://10.204.51.65:9200"]
    user => "elastic"
    password => "123456"
    index => "traefik-logs-%{+yyyy.MM.dd}"
    #index => "%{Ingressroute_name}-%{+YYYY.MM.dd}" #### 根据Ingressroute_name名称创建指定的index
    #document_id => "%{Ingressroute_name}" ###document_id等于Ingressroute_name
  } 
}
